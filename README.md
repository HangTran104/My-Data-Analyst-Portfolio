<h1 style = 'color:darkblue; text-align:center'>My-Portfolio</h1>
This page aims to navigate to my projects page. These projects may include Data Visualization, EDA process, how to use some basic statistics when performing statistical analysis, the ETL process, and building models for predictions.
<br>
<br>

<h3 style = 'color:black; text-align:left'>1. Data Mining - House Price Dataset </h3> 
Link: https://github.com/HangTran104/House-Price-Prediction/blob/main/Buseness_and_DataUnderstanding.ipynb
<br>
<br>
<h3 style = 'color:black; text-align:left'>2. House Price Prediction Project</h3> 
Skills: Pandas for Data cleaning and understanding, EDA process. Build Pipeline from transformation to modeling process. Models: Ridge, LinearRegression, RandomForestRegressor, SVM, XGBoost, DecisionTreeRegressor, Lasso, KNeighborsRegressor, GaussianProcessRegressor.
<br>
This project uses the Ho Chi Minh House dataset to:
<br>
- Survey house prices of Ho Chi Minh City using data visualizations and descriptive statistics.
- <br>
- Build a model to predict house prices based on house features based on regression models.
Link: https://github.com/HangTran104/House-Price-Prediction
<br>
<br>
<h3 style = 'color:black; text-align:left'>3. Super Market Food Analysis - Customers Segmentation Project</h3> 
The supermarket is one kind of business retailer that brings a wide range of goods fulfilling the basic demand of people. As a result, their type of products and customers are diverse. There some data techniques can be used to discover more about customer patterns and their behavior so that the supermarket ease to segment the customers and apply the appropriate marketing promotion based on customer classes. Besides, the Apriori technique will help them organize their goods logically to attract customers easily.
<br>
This project performs Customer segmentation and food supermarket analysis. This project uses the UK supermarket e-commerce dataset to clean data, perform EDA, and build a model for clustering supermarket customers into various groups with particular patterns. Business analysis of the characteristics of these groups to help the enterprise understand more about their customers and plan appropriate marketing strategies.
<br>
Techniques: RFM and LRFMP coupled with the KMeans Model for customer segmentation. Apriori for Association Rule Mining to determine the relationship between products. Pandas for Data Cleaning and Exploratory Data Analysis. Matplotlib and Seaborn for Visualization.
<br>
Link: https://github.com/HangTran104/CustomerSegmentation_SuperMarketFoodProducts/blob/main/MallCustomers.ipynb
<br>
<br>

<h3 style = 'color:black; text-align:left'>4. Build a model for Credit Risk Prediction Project</h3>
Link: https://github.com/HangTran104/BUILD-MODELLER-FOR-CREDIT-RISK-ACCESSMENT
<br>
This project describes the whole process of building models for credit risk prediction after EDA. In the first stages of the process, I try to load data, transform and standardize data. In the second stage, I split data into train and test datasets and survey features to define the most important attributes related to customers that affect the default behavior when they loan money from investors or bankers. Finally, various kinds of models were built and evaluated based on their accuracy and time of performance.
<br>
Techniques: transformation techniques and regression models.
<br>
<br>

<h3 style = 'color:black; text-align:left'>6. Build Web Scrawler using Beautifulsoup and Selenium</h3> 
Link: https://github.com/HangTran104/WEB-SCRWLER
<br>
In the real world of business, an enterprise can store its data internally for government audit purposes or retrieve the data when needed to analyze for historical status of operations surveys or forecast/predict revenue in the future. However, because business is a complicated process that has been impacted by different types of factors from the economy, politics, and environments. Therefore, sometimes many have to collect data outside of other websites and or buy from other sources. Consequently, crawler tools play an important role in helping enterprises collect external sources of data for their survey projects.
The project aims to build a simple web crawler using BeautifulSoup to collect data from a webpage.
